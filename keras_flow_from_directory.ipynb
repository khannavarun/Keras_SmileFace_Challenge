{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/vkhanna/Documents/GitHub/Keras_SmileFace_Challenge/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/vkhanna/Documents/GitHub/Keras_SmileFace_Challenge/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/vkhanna/Documents/GitHub/Keras_SmileFace_Challenge/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/vkhanna/Documents/GitHub/Keras_SmileFace_Challenge/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/vkhanna/Documents/GitHub/Keras_SmileFace_Challenge/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/vkhanna/Documents/GitHub/Keras_SmileFace_Challenge/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/vkhanna/Documents/GitHub/Keras_SmileFace_Challenge/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/vkhanna/Documents/GitHub/Keras_SmileFace_Challenge/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/vkhanna/Documents/GitHub/Keras_SmileFace_Challenge/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/vkhanna/Documents/GitHub/Keras_SmileFace_Challenge/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/vkhanna/Documents/GitHub/Keras_SmileFace_Challenge/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/vkhanna/Documents/GitHub/Keras_SmileFace_Challenge/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Could use larger dimensions, but will make training\n",
    "# times much much longer\n",
    "img_width, img_height = (75, 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 320 images belonging to 2 classes.\n",
      "Found 80 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = 'FEI/train'\n",
    "test_dir = 'FEI/test'\n",
    "\n",
    "epochs = 40\n",
    "batch_size = 8\n",
    "num_train_samples = 320\n",
    "num_test_samples  =  80\n",
    "\n",
    "# perform random transformations so that the\n",
    "# data is more varied\n",
    "train_datagen = ImageDataGenerator(rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "test_datagen  = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=(img_width, img_height),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='binary',\n",
    "                                                    shuffle=True)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(test_dir,\n",
    "                                                        target_size=(img_width, img_height),\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='binary',\n",
    "                                                        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 75, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), activation=\"relu\", input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (5, 5), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Convolution is done, so make the fully connected layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Drop 50% of the neurons\n",
    "model.add(Dense(25, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# compilation\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "40/40 [==============================] - 3s 67ms/step - loss: 0.6963 - acc: 0.5188 - val_loss: 0.6968 - val_acc: 0.4625\n",
      "Epoch 2/40\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.6911 - acc: 0.5656 - val_loss: 0.6867 - val_acc: 0.7000\n",
      "Epoch 3/40\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.6832 - acc: 0.5719 - val_loss: 0.6866 - val_acc: 0.5250\n",
      "Epoch 4/40\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.6805 - acc: 0.5625 - val_loss: 0.6560 - val_acc: 0.6375\n",
      "Epoch 5/40\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.6748 - acc: 0.6000 - val_loss: 0.6145 - val_acc: 0.6125\n",
      "Epoch 6/40\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.6665 - acc: 0.6156 - val_loss: 0.5850 - val_acc: 0.7750\n",
      "Epoch 7/40\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.6662 - acc: 0.5906 - val_loss: 0.6774 - val_acc: 0.6250\n",
      "Epoch 8/40\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.6754 - acc: 0.6187 - val_loss: 0.6483 - val_acc: 0.6125\n",
      "Epoch 9/40\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.6418 - acc: 0.6375 - val_loss: 0.6664 - val_acc: 0.5875\n",
      "Epoch 10/40\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.6309 - acc: 0.6469 - val_loss: 0.5404 - val_acc: 0.6875\n",
      "Epoch 11/40\n",
      "40/40 [==============================] - 3s 67ms/step - loss: 0.6270 - acc: 0.6344 - val_loss: 0.4772 - val_acc: 0.8125\n",
      "Epoch 12/40\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 0.6111 - acc: 0.6719 - val_loss: 0.4478 - val_acc: 0.7875\n",
      "Epoch 13/40\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.6863 - acc: 0.6062 - val_loss: 0.6003 - val_acc: 0.5750\n",
      "Epoch 14/40\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.6427 - acc: 0.6562 - val_loss: 0.5139 - val_acc: 0.7000\n",
      "Epoch 15/40\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.5929 - acc: 0.6719 - val_loss: 0.4773 - val_acc: 0.8125\n",
      "Epoch 16/40\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.5384 - acc: 0.7469 - val_loss: 0.4731 - val_acc: 0.7125\n",
      "Epoch 17/40\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.5639 - acc: 0.7281 - val_loss: 0.4245 - val_acc: 0.8375\n",
      "Epoch 18/40\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.5167 - acc: 0.7375 - val_loss: 0.2907 - val_acc: 0.8875\n",
      "Epoch 19/40\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.5030 - acc: 0.7531 - val_loss: 0.3542 - val_acc: 0.8375\n",
      "Epoch 20/40\n",
      "40/40 [==============================] - 3s 68ms/step - loss: 0.4874 - acc: 0.7563 - val_loss: 0.4746 - val_acc: 0.8125\n",
      "Epoch 21/40\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 0.4400 - acc: 0.7938 - val_loss: 0.3937 - val_acc: 0.8750\n",
      "Epoch 22/40\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.4114 - acc: 0.8125 - val_loss: 0.3225 - val_acc: 0.8125\n",
      "Epoch 23/40\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.3656 - acc: 0.8438 - val_loss: 0.3449 - val_acc: 0.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13bd2e518>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=num_train_samples // batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=num_test_samples // batch_size,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
